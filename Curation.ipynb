{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "import heapq\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_count(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "    return word_frequencies\n",
    "\n",
    "def weighted_freq(word_frequencies):\n",
    "    maximum_frequncy = sum(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    \n",
    "    return word_frequencies\n",
    "\n",
    "def sentence_scores_calc(word_frequencies,tokenized_sentence):\n",
    "    sentence_scores = {}\n",
    "    for sent in tokenized_sentence:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    return sentence_scores\n",
    "\n",
    "def summarizer(text):\n",
    "    word_frequencies = word_freq_count(text)\n",
    "    word_frequencies = weighted_freq(word_frequencies)\n",
    "    sentence_list = nltk.sent_tokenize(text)\n",
    "    sentence_scores = sentence_scores_calc(word_frequencies, sentence_list)\n",
    "    summary_sentences = heapq.nlargest(12, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/praneeth/Downloads/gtd1993_0221dist.xlsx')\n",
    "corpus = df['summary']\n",
    "\n",
    "def preprocess_function(raw_text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(raw_text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    stems = []\n",
    "    for t in tokens:\n",
    "        stems.append(porter.stem(t))\n",
    "    return stems\n",
    "\n",
    "corpus_array = []\n",
    "for i in range(0,len(df)):\n",
    "    word = preprocess_function(str(df['summary'][i]))\n",
    "    corpus_array.append(word)\n",
    "\n",
    "final_corpus = []\n",
    "for i in range(0,len(corpus_array)):\n",
    "    for ele in corpus_array[i]:\n",
    "        if ele not in final_corpus:\n",
    "            final_corpus.append(ele)\n",
    "ref_corpus = [item for item in final_corpus if not item.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextFromURL(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    text = ' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.206896551724135"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = getTextFromURL('https://www.thequint.com/news/world/unsc-skips-taliban-reference-in-statement-on-terror')\n",
    "summary = summarizer(raw_text)\n",
    "preprocessed_text = preprocess_function(summary)\n",
    "score = 0\n",
    "for i in preprocessed_text:\n",
    "    if i in ref_corpus:\n",
    "        score = score + 1\n",
    "\n",
    "final_score = (score/len(preprocessed_text)) * 100\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.moneycontrol.com/news/world/afghanistan-taliban-crisis-live-updates-joe-biden-attends-grim-homecoming-for-us-troops-killed-in-afghanistan-attack-7404891.html Terror Score:  61.04651162790697\n",
      "https://www.ndtv.com/world-news/taliban-supreme-leader-hibatullah-akhundzada-in-afghanistans-kandahar-city-says-spokesman-report-2523108 Terror Score:  46.794871794871796\n",
      "https://www.business-standard.com/article/current-affairs/afghanistan-crisis-live-updates-terror-attack-taliban-farmers-india-top-highlights-121083000021_1.html Terror Score:  36.666666666666664\n",
      "https://en.wikipedia.org/wiki/Taliban Terror Score:  40.816326530612244\n",
      "https://en.wikipedia.org/wiki/Taliban_insurgency Terror Score:  54.54545454545454\n",
      "https://en.wikipedia.org/wiki/History_of_Taliban Terror Score:  51.515151515151516\n",
      "https://en.wikipedia.org/wiki/Tehrik-i-Taliban_Pakistan Terror Score:  50.77720207253886\n",
      "https://en.wikipedia.org/wiki/Deobandi Terror Score:  42.38095238095238\n",
      "https://www.bbc.com/news/world-south-asia-11451718 Terror Score:  68.75\n",
      "https://edition.cnn.com/2021/08/16/middleeast/taliban-control-afghanistan-explained-intl-hnk/index.html Terror Score:  30.0\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "query = \"Taliban\"\n",
    "for j in search(query, tld=\"co.in\", num=10, stop=10, pause=2):\n",
    "    raw_text = getTextFromURL(j)\n",
    "    summary = summarizer(raw_text)\n",
    "    preprocessed_text = preprocess_function(summary)\n",
    "    score = 0\n",
    "    for i in preprocessed_text:\n",
    "        if i in ref_corpus:\n",
    "            score = score + 1\n",
    "    if len(preprocessed_text) == 0:\n",
    "        final_score = 0\n",
    "    else:\n",
    "        final_score = (score/len(preprocessed_text)) * 100\n",
    "    print(j, end = ' ')\n",
    "    print(\"Terror Score: \", end = ' ')\n",
    "    print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for i in preprocessed_text:\n",
    "    if i in ref_corpus:\n",
    "        score = score + 1\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3620689655172414"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score / len(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
